vqvae      :
  _target_           : src.model.vqvae.VQVAE
  num_hidden         : 128
  num_residual_layer : 2
  num_residual_hidden: 32
  num_embedding      : 512
  embedding_dim      : 64
  commitment_cost    : 0.25
  learning_rate      : 1e-4
  sample_rate        : ${data.target_sample_rate}
  checkpoint_dir     : ${paths.checkpoint_dir}
  codebook_file      : ${paths.codebook_file}
transformer:
  __target__    : src.model.transformer.Transformer
  sample_rate   : ${data.target_sample_rate}
  frame_length  : ${data.target_sample_duration}
  learning_rate : 1e-4
  checkpoint_dir: ${paths.checkpoint_dir}
  num_layers    : 4
  num_heads     : 8
  hidden_dim    : 512

